<!doctype html>
<html>
<head>
		<title>LAWRENCE KIM</title>
		<meta charset="utf-8" />
		<meta name="viewport" content="width=device-width, initial-scale=1" />
		<link rel="stylesheet" href="../../assets/css/main.css" />
	</head>

<body>
	<!-- Header -->
			<header id="header">
				<h1><strong><a href="../../index.html">Lawrence Kim </a></strong> </h1>
				<nav id="nav">
					<ul>
						<li><a href="../../index.html">Home</a></li>
						<li><a href="../../index.html#research">Research</a></li>
						<li><a href="../../publication.html">Publication</a></li>
						<li><a href="../../index.html#press">Press</a></li>
					</ul>
				</nav>
			</header>

			<a href="#menu" class="navPanelToggle"><span class="fa fa-bars"></span></a>
	<!-- Main -->
		<section id="main" class="wrapper">
				<div class="container">
					<header class="major special">
						<h2>React to This! How Humans Challenge Interactive Agents using Nonverbal Behaviors</h2> <br>
						<h4><font color="#959595">Chuxuan Zhang, Bermet Burkanova, Lawrence H. Kim, Lauren Yip, Ugo Cupcic, Stephane Lallee, and Angelica Lim</font></h4>
					</header>
					<section>
												
<!--
						<div class="box alt">
							<div class="row 50% uniform" >
								<div class="5u$" ><span class="image fit"><img src="../../images/RoboticPresence.gif" alt=""/></span></div>
							</div>
						</div>
-->
						<div class="box alt">
							<div class="row 50% uniform" >
								<div class="10u$" ><span class="image fit"><img src="../2024-ReactToThis/Pictures/Teaser.png" alt="" />
									<figcaption></figcaption></span></div>
							</div>
						</div>
						
						
						<h3>Abstract</h3>
						<p>How do people use their faces and bodies to test the interactive abilities of a robot? Making lively, believable agents is often seen as a goal for robots and virtual agents but believability can easily break down. In this Wizard-ofOz (WoZ) study, we observed 1169 nonverbal interactions between 20 participants and 6 types of agents. We collected the nonverbal behaviors participants used to challenge the characters physically, emotionally, and socially. The participants interacted freely with humanoid and non-humanoid forms: a robot, a human, a penguin, a pufferfish, a banana, and a toilet. We present a human behavior codebook of 188 unique nonverbal behaviors used by humans to test the virtual characters. The insights and design strategies drawn from video observations aim to help build more interaction-aware and believable robots, especially when humans push them to their limits.</p>
						
						<hr />
						
						<h3>Presentation</h3>
						
						<iframe width="560" height="315" src="https://www.youtube.com/watch?v=QRi5o5v_leY&ab_channel=SFURosieLab" frameborder="0" allowfullscreen></iframe>
						
						<hr />
						
						
						<h3>Paper</h3>
						<header class="major">
							<h4>React to This! How Humans Challenge Interactive Agents using Nonverbal Behaviors<font color="cfb282"> </font><font color="#959595"><a href="../2024-ReactToThis/IROS-preprint.pdf" target="_blank"> [PDF]</a></font></h4>
							<p>Chuxuan Zhang, Bermet Burkanova, Lawrence H. Kim, Lauren Yip, Ugo Cupcic, Stephane Lallee, and Angelica Lim<br>
							IROS 2024</p>
						</header>
						
						

			
					</section>
				</div>
		</section>
</body>
</html>
